{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DIN (Electronics 10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argparser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--lr', default=0.1, help='learning rate', type=float)\n",
    "    parser.add_argument('--train_batch_size', default=32, help='batch size', type=int)\n",
    "    parser.add_argument('--test_batch_size', default=512, help='batch size', type=int)\n",
    "    parser.add_argument('--epochs', default=10, help='number of epochs', type=int)\n",
    "    parser.add_argument('--print_step', default=1000, help='step size for print log', type=int)\n",
    "\n",
    "    parser.add_argument('--dataset_dir', default='./data/', help='dataset path')\n",
    "    parser.add_argument('--model_path', default='./models/', help='model load path', type=str)\n",
    "    parser.add_argument('--log_path', default='./logs/', help='log path fot tensorboard', type=str)\n",
    "    parser.add_argument('--is_reuse', default=False)\n",
    "    parser.add_argument('--multi_gpu', default=False)\n",
    "\n",
    "    parser.add_argument('--user_count', default=192403, help='number of users', type=int)\n",
    "    parser.add_argument('--item_count', default=63001, help='number of items', type=int)\n",
    "    parser.add_argument('--cate_count', default=801, help='number of categories', type=int)\n",
    "\n",
    "    parser.add_argument('--user_dim', default=128, help='dimension of user', type=int)\n",
    "    parser.add_argument('--item_dim', default=64, help='dimension of item', type=int)\n",
    "    parser.add_argument('--cate_dim', default=64, help='dimension of category', type=int)\n",
    "\n",
    "    parser.add_argument('--dim_layers', default=[80,40,1], type=int)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [''] # add this to resolve the execution problem, when all arguments have a default value\n",
    "args = argparser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset includes reviews (ratings, text, helpfulness votes), product metadata (descriptions, category information, price, brand, and image features), and links (also viewed/also bought graphs).\n",
    "\n",
    "**Reviews:**\n",
    "* `asin`: ID of the product\n",
    "* `reviewerID`: ID of the reviewer\n",
    "* `unixReviewTime`: time of the review (unix time)\n",
    "\n",
    "**Metadata:**\n",
    "* `asin`: ID of the product\n",
    "* `categories`: list of categories the product belongs to\n",
    "\n",
    "Metadata includes descriptions, price, sales-rank, brand info, and co-purchasing links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the reviews json file as `reviews_df`\n",
    "# reviews_Electronics_5\n",
    "# Magazine_Subscriptions\n",
    "# Software\n",
    "with open('./data/raw_data/reviews_Electronics_5.json') as fin:\n",
    "    df = {}\n",
    "    for i, line in enumerate(fin):\n",
    "        df[i] = eval(line)\n",
    "        # df[i] = json.loads(line)\n",
    "    reviews_df = pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AO94DHGC771SJ</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>amazdnu</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gotta have GPS!</td>\n",
       "      <td>1370131200</td>\n",
       "      <td>06 2, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMO214LNFCEI4</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[12, 15]</td>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Very Disappointed</td>\n",
       "      <td>1290643200</td>\n",
       "      <td>11 25, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3N7T0DY83Y4IG</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>C. A. Freeman</td>\n",
       "      <td>[43, 45]</td>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1st impression</td>\n",
       "      <td>1283990400</td>\n",
       "      <td>09 9, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1H8PY3QHMQQA0</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Dave M. Shaw \"mack dave\"</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Great grafics, POOR GPS</td>\n",
       "      <td>1290556800</td>\n",
       "      <td>11 24, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A24EV6RXELQZ63</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Wayne Smith</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Major issues, only excuses for support</td>\n",
       "      <td>1317254400</td>\n",
       "      <td>09 29, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689183</th>\n",
       "      <td>A34BZM6S9L7QI4</td>\n",
       "      <td>B00LGQ6HL8</td>\n",
       "      <td>Candy Cane \"Is it just me?\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Burned these in before listening to them for a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Boom -- Pop -- Pow.  These deliver.</td>\n",
       "      <td>1405555200</td>\n",
       "      <td>07 17, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689184</th>\n",
       "      <td>A1G650TTTHEAL5</td>\n",
       "      <td>B00LGQ6HL8</td>\n",
       "      <td>Charles Spanky \"Zumina Reviews\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Some people like DJ style headphones or earbud...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Thin and light, without compromising on sound ...</td>\n",
       "      <td>1405382400</td>\n",
       "      <td>07 15, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689185</th>\n",
       "      <td>A25C2M3QF9G7OQ</td>\n",
       "      <td>B00LGQ6HL8</td>\n",
       "      <td>Comdet</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I&amp;#8217;m a big fan of the Brainwavz S1 (actua...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Same form factor and durability as the S1 with...</td>\n",
       "      <td>1405555200</td>\n",
       "      <td>07 17, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689186</th>\n",
       "      <td>A1E1LEVQ9VQNK</td>\n",
       "      <td>B00LGQ6HL8</td>\n",
       "      <td>J. Chambers</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I've used theBrainwavz S1 In Ear Headphones, a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Superb audio quality in a very comfortable set...</td>\n",
       "      <td>1405641600</td>\n",
       "      <td>07 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689187</th>\n",
       "      <td>A2NYK9KWFMJV4Y</td>\n",
       "      <td>B00LGQ6HL8</td>\n",
       "      <td>Mike Tarrani \"Jazz Drummer\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Normally when I receive a review sample I can ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Exceptional sound</td>\n",
       "      <td>1405209600</td>\n",
       "      <td>07 13, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1689188 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             reviewerID        asin                     reviewerName  \\\n",
       "0         AO94DHGC771SJ  0528881469                          amazdnu   \n",
       "1         AMO214LNFCEI4  0528881469                  Amazon Customer   \n",
       "2        A3N7T0DY83Y4IG  0528881469                    C. A. Freeman   \n",
       "3        A1H8PY3QHMQQA0  0528881469         Dave M. Shaw \"mack dave\"   \n",
       "4        A24EV6RXELQZ63  0528881469                      Wayne Smith   \n",
       "...                 ...         ...                              ...   \n",
       "1689183  A34BZM6S9L7QI4  B00LGQ6HL8      Candy Cane \"Is it just me?\"   \n",
       "1689184  A1G650TTTHEAL5  B00LGQ6HL8  Charles Spanky \"Zumina Reviews\"   \n",
       "1689185  A25C2M3QF9G7OQ  B00LGQ6HL8                           Comdet   \n",
       "1689186   A1E1LEVQ9VQNK  B00LGQ6HL8                      J. Chambers   \n",
       "1689187  A2NYK9KWFMJV4Y  B00LGQ6HL8      Mike Tarrani \"Jazz Drummer\"   \n",
       "\n",
       "          helpful                                         reviewText  overall  \\\n",
       "0          [0, 0]  We got this GPS for my husband who is an (OTR)...      5.0   \n",
       "1        [12, 15]  I'm a professional OTR truck driver, and I bou...      1.0   \n",
       "2        [43, 45]  Well, what can I say.  I've had this unit in m...      3.0   \n",
       "3         [9, 10]  Not going to write a long review, even thought...      2.0   \n",
       "4          [0, 0]  I've had mine for a year and here's what we go...      1.0   \n",
       "...           ...                                                ...      ...   \n",
       "1689183    [1, 1]  Burned these in before listening to them for a...      5.0   \n",
       "1689184    [0, 0]  Some people like DJ style headphones or earbud...      5.0   \n",
       "1689185    [0, 0]  I&#8217;m a big fan of the Brainwavz S1 (actua...      5.0   \n",
       "1689186    [0, 0]  I've used theBrainwavz S1 In Ear Headphones, a...      5.0   \n",
       "1689187    [0, 0]  Normally when I receive a review sample I can ...      5.0   \n",
       "\n",
       "                                                   summary  unixReviewTime  \\\n",
       "0                                          Gotta have GPS!      1370131200   \n",
       "1                                        Very Disappointed      1290643200   \n",
       "2                                           1st impression      1283990400   \n",
       "3                                  Great grafics, POOR GPS      1290556800   \n",
       "4                   Major issues, only excuses for support      1317254400   \n",
       "...                                                    ...             ...   \n",
       "1689183                Boom -- Pop -- Pow.  These deliver.      1405555200   \n",
       "1689184  Thin and light, without compromising on sound ...      1405382400   \n",
       "1689185  Same form factor and durability as the S1 with...      1405555200   \n",
       "1689186  Superb audio quality in a very comfortable set...      1405641600   \n",
       "1689187                                  Exceptional sound      1405209600   \n",
       "\n",
       "          reviewTime  \n",
       "0         06 2, 2013  \n",
       "1        11 25, 2010  \n",
       "2         09 9, 2010  \n",
       "3        11 24, 2010  \n",
       "4        09 29, 2011  \n",
       "...              ...  \n",
       "1689183  07 17, 2014  \n",
       "1689184  07 15, 2014  \n",
       "1689185  07 17, 2014  \n",
       "1689186  07 18, 2014  \n",
       "1689187  07 13, 2014  \n",
       "\n",
       "[1689188 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the overall reviews dataset\n",
    "# reviews_Electronics_5: 1689188 rows × 9 columns\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only the first n/10 groups\n",
    "reviews_df_groupby = reviews_df.groupby('reviewerID')\n",
    "grouped = [g[1] for g in list(reviews_df_groupby)[:int(len(reviews_df_groupby)/10)]]\n",
    "reviews_df = pd.concat(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321546</th>\n",
       "      <td>A000715434M800HLCENK9</td>\n",
       "      <td>B000UYYZ0M</td>\n",
       "      <td>DP</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>So the screen itself is OK. it is an actual sc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Spring is not strong</td>\n",
       "      <td>1400457600</td>\n",
       "      <td>05 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450446</th>\n",
       "      <td>A000715434M800HLCENK9</td>\n",
       "      <td>B001EHAI6Y</td>\n",
       "      <td>DP</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I had a complicated set up for my screen. I ne...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Exactly what i wanted</td>\n",
       "      <td>1400457600</td>\n",
       "      <td>05 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738088</th>\n",
       "      <td>A000715434M800HLCENK9</td>\n",
       "      <td>B003AFONFU</td>\n",
       "      <td>DP</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>The mount is good if you account for the play ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>beware of the play</td>\n",
       "      <td>1400457600</td>\n",
       "      <td>05 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766200</th>\n",
       "      <td>A000715434M800HLCENK9</td>\n",
       "      <td>B003ES5ZUU</td>\n",
       "      <td>DP</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>For some reason this product doesnt work that ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Not great with Apple TV</td>\n",
       "      <td>1400457600</td>\n",
       "      <td>05 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678142</th>\n",
       "      <td>A000715434M800HLCENK9</td>\n",
       "      <td>B00HMZG3YS</td>\n",
       "      <td>DP</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Great box Exactly what i needed. it isnt water...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Very good</td>\n",
       "      <td>1400457600</td>\n",
       "      <td>05 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565072</th>\n",
       "      <td>A1DJR7B306SJIY</td>\n",
       "      <td>B0026RHPSU</td>\n",
       "      <td>James \"Jim\"</td>\n",
       "      <td>[8, 13]</td>\n",
       "      <td>In my opinion this is a very poor choice of wa...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Why buy an expensive dock?</td>\n",
       "      <td>1295308800</td>\n",
       "      <td>01 18, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697886</th>\n",
       "      <td>A1DJR7B306SJIY</td>\n",
       "      <td>B0031QNP8O</td>\n",
       "      <td>James \"Jim\"</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>I had a Garmin Trek prior to buying this. I wa...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Difficult to operate for the neophyte</td>\n",
       "      <td>1381622400</td>\n",
       "      <td>10 13, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742523</th>\n",
       "      <td>A1DJR7B306SJIY</td>\n",
       "      <td>B003BEDQR6</td>\n",
       "      <td>James \"Jim\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>For the price, this is a great system. The fac...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good sound</td>\n",
       "      <td>1358640000</td>\n",
       "      <td>01 20, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453061</th>\n",
       "      <td>A1DJR7B306SJIY</td>\n",
       "      <td>B0097BEF1S</td>\n",
       "      <td>James \"Jim\"</td>\n",
       "      <td>[7, 27]</td>\n",
       "      <td>The main gripes I have about this product is n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Apple is deceitful</td>\n",
       "      <td>1368662400</td>\n",
       "      <td>05 16, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684366</th>\n",
       "      <td>A1DJR7B306SJIY</td>\n",
       "      <td>B00INNP5VU</td>\n",
       "      <td>James \"Jim\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>It sure has a lot of free things on it. I'm no...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Nice</td>\n",
       "      <td>1396569600</td>\n",
       "      <td>04 4, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168581 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    reviewerID        asin reviewerName  helpful  \\\n",
       "321546   A000715434M800HLCENK9  B000UYYZ0M           DP   [0, 0]   \n",
       "450446   A000715434M800HLCENK9  B001EHAI6Y           DP   [0, 0]   \n",
       "738088   A000715434M800HLCENK9  B003AFONFU           DP   [1, 1]   \n",
       "766200   A000715434M800HLCENK9  B003ES5ZUU           DP   [0, 0]   \n",
       "1678142  A000715434M800HLCENK9  B00HMZG3YS           DP   [0, 0]   \n",
       "...                        ...         ...          ...      ...   \n",
       "565072          A1DJR7B306SJIY  B0026RHPSU  James \"Jim\"  [8, 13]   \n",
       "697886          A1DJR7B306SJIY  B0031QNP8O  James \"Jim\"   [1, 3]   \n",
       "742523          A1DJR7B306SJIY  B003BEDQR6  James \"Jim\"   [0, 0]   \n",
       "1453061         A1DJR7B306SJIY  B0097BEF1S  James \"Jim\"  [7, 27]   \n",
       "1684366         A1DJR7B306SJIY  B00INNP5VU  James \"Jim\"   [0, 0]   \n",
       "\n",
       "                                                reviewText  overall  \\\n",
       "321546   So the screen itself is OK. it is an actual sc...      1.0   \n",
       "450446   I had a complicated set up for my screen. I ne...      5.0   \n",
       "738088   The mount is good if you account for the play ...      3.0   \n",
       "766200   For some reason this product doesnt work that ...      2.0   \n",
       "1678142  Great box Exactly what i needed. it isnt water...      5.0   \n",
       "...                                                    ...      ...   \n",
       "565072   In my opinion this is a very poor choice of wa...      1.0   \n",
       "697886   I had a Garmin Trek prior to buying this. I wa...      2.0   \n",
       "742523   For the price, this is a great system. The fac...      4.0   \n",
       "1453061  The main gripes I have about this product is n...      1.0   \n",
       "1684366  It sure has a lot of free things on it. I'm no...      5.0   \n",
       "\n",
       "                                       summary  unixReviewTime   reviewTime  \n",
       "321546                    Spring is not strong      1400457600  05 19, 2014  \n",
       "450446                   Exactly what i wanted      1400457600  05 19, 2014  \n",
       "738088                      beware of the play      1400457600  05 19, 2014  \n",
       "766200                 Not great with Apple TV      1400457600  05 19, 2014  \n",
       "1678142                              Very good      1400457600  05 19, 2014  \n",
       "...                                        ...             ...          ...  \n",
       "565072              Why buy an expensive dock?      1295308800  01 18, 2011  \n",
       "697886   Difficult to operate for the neophyte      1381622400  10 13, 2013  \n",
       "742523                              Good sound      1358640000  01 20, 2013  \n",
       "1453061                     Apple is deceitful      1368662400  05 16, 2013  \n",
       "1684366                                   Nice      1396569600   04 4, 2014  \n",
       "\n",
       "[168581 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the object `reviews_df` to the open file object `reviews.pkl`\n",
    "with open('./data/reviews.pkl', 'wb') as f:\n",
    "    pickle.dump(reviews_df, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the product metadata json file as `meta_df`\n",
    "with open('./data/raw_data/meta_Electronics.json') as fin:\n",
    "    df = {}\n",
    "    for i, line in enumerate(fin):\n",
    "        df[i] = eval(line)\n",
    "        # df[i] = json.loads(line)\n",
    "    meta_df = pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>imUrl</th>\n",
       "      <th>description</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>related</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0132793040</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/31JIPhp%...</td>\n",
       "      <td>The Kelby Training DVD Mastering Blend Modes i...</td>\n",
       "      <td>[[Electronics, Computers &amp; Accessories, Cables...</td>\n",
       "      <td>Kelby Training DVD: Mastering Blend Modes in A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0321732944</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/31uogm6Y...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Electronics, Computers &amp; Accessories, Cables...</td>\n",
       "      <td>Kelby Training DVD: Adobe Photoshop CS5 Crash ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0439886341</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51k0qa8f...</td>\n",
       "      <td>Digital Organizer and Messenger</td>\n",
       "      <td>[[Electronics, Computers &amp; Accessories, PDAs, ...</td>\n",
       "      <td>Digital Organizer and Messenger</td>\n",
       "      <td>8.15</td>\n",
       "      <td>{'Electronics': 144944}</td>\n",
       "      <td>{'also_viewed': ['0545016266', 'B009ECM8QY', '...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0511189877</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41HaAhbv...</td>\n",
       "      <td>The CLIKR-5 UR5U-8780L remote control is desig...</td>\n",
       "      <td>[[Electronics, Accessories &amp; Supplies, Audio &amp;...</td>\n",
       "      <td>CLIKR-5 Time Warner Cable Remote Control UR5U-...</td>\n",
       "      <td>23.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'also_viewed': ['B001KC08A4', 'B00KUL8O0W', '...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0528881469</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51FnRkJq...</td>\n",
       "      <td>Like its award-winning predecessor, the Intell...</td>\n",
       "      <td>[[Electronics, GPS &amp; Navigation, Vehicle GPS, ...</td>\n",
       "      <td>Rand McNally 528881469 7-inch Intelliroute TND...</td>\n",
       "      <td>299.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'also_viewed': ['B006ZOI9OY', 'B00C7FKT2A', '...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498191</th>\n",
       "      <td>BT008V9J9U</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/313e6SJm...</td>\n",
       "      <td>Vehicle suction cup mount (replacement) NOTICE...</td>\n",
       "      <td>[[Electronics, GPS &amp; Navigation, GPS System Ac...</td>\n",
       "      <td>Suction Cup Mount</td>\n",
       "      <td>21.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'buy_after_viewing': ['B000EPFCC2']}</td>\n",
       "      <td>Garmin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498192</th>\n",
       "      <td>BT008SXQ4C</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/31oF9oNv...</td>\n",
       "      <td>Quatech - 1 Port PCMCIA to DB-25 Parallel Adap...</td>\n",
       "      <td>[[Electronics, Computers &amp; Accessories, Cables...</td>\n",
       "      <td>Parallel PCMCIA Card 1PORT Epp</td>\n",
       "      <td>23.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'also_bought': ['B000SR2H4W', 'B001Q7X0W6'], ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498193</th>\n",
       "      <td>BT008G3W52</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/21WIrX5f...</td>\n",
       "      <td>C2G - 5m Ultma USB 2.0 A Mini B Cble</td>\n",
       "      <td>[[Electronics, Computers &amp; Accessories, Cables...</td>\n",
       "      <td>C2G / Cables to Go 5M Ultima USB 2.0 Cable</td>\n",
       "      <td>18.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'bought_together': ['B0002D6QJO'], 'buy_after...</td>\n",
       "      <td>C2G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498194</th>\n",
       "      <td>BT008UKTMW</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41TNAVmf...</td>\n",
       "      <td>Keyboard drawer.</td>\n",
       "      <td>[[Electronics, Computers &amp; Accessories, Cables...</td>\n",
       "      <td>Underdesk Keyboard Drawer</td>\n",
       "      <td>25.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'also_viewed': ['B0002LD0ZY', 'B0002LCZP0', '...</td>\n",
       "      <td>Fellowes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498195</th>\n",
       "      <td>BT008T2BGK</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41x-15rR...</td>\n",
       "      <td>Garmin USB to R232 Converter CableUSB to RS232...</td>\n",
       "      <td>[[Electronics, Computers &amp; Accessories, Cables...</td>\n",
       "      <td>USB To R232 Converter Cable</td>\n",
       "      <td>62.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'also_viewed': ['B0007T27H8', 'B00425S1H8', '...</td>\n",
       "      <td>Garmin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498196 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin                                              imUrl  \\\n",
       "0       0132793040  http://ecx.images-amazon.com/images/I/31JIPhp%...   \n",
       "1       0321732944  http://ecx.images-amazon.com/images/I/31uogm6Y...   \n",
       "2       0439886341  http://ecx.images-amazon.com/images/I/51k0qa8f...   \n",
       "3       0511189877  http://ecx.images-amazon.com/images/I/41HaAhbv...   \n",
       "4       0528881469  http://ecx.images-amazon.com/images/I/51FnRkJq...   \n",
       "...            ...                                                ...   \n",
       "498191  BT008V9J9U  http://ecx.images-amazon.com/images/I/313e6SJm...   \n",
       "498192  BT008SXQ4C  http://ecx.images-amazon.com/images/I/31oF9oNv...   \n",
       "498193  BT008G3W52  http://ecx.images-amazon.com/images/I/21WIrX5f...   \n",
       "498194  BT008UKTMW  http://ecx.images-amazon.com/images/I/41TNAVmf...   \n",
       "498195  BT008T2BGK  http://ecx.images-amazon.com/images/I/41x-15rR...   \n",
       "\n",
       "                                              description  \\\n",
       "0       The Kelby Training DVD Mastering Blend Modes i...   \n",
       "1                                                     NaN   \n",
       "2                         Digital Organizer and Messenger   \n",
       "3       The CLIKR-5 UR5U-8780L remote control is desig...   \n",
       "4       Like its award-winning predecessor, the Intell...   \n",
       "...                                                   ...   \n",
       "498191  Vehicle suction cup mount (replacement) NOTICE...   \n",
       "498192  Quatech - 1 Port PCMCIA to DB-25 Parallel Adap...   \n",
       "498193               C2G - 5m Ultma USB 2.0 A Mini B Cble   \n",
       "498194                                   Keyboard drawer.   \n",
       "498195  Garmin USB to R232 Converter CableUSB to RS232...   \n",
       "\n",
       "                                               categories  \\\n",
       "0       [[Electronics, Computers & Accessories, Cables...   \n",
       "1       [[Electronics, Computers & Accessories, Cables...   \n",
       "2       [[Electronics, Computers & Accessories, PDAs, ...   \n",
       "3       [[Electronics, Accessories & Supplies, Audio &...   \n",
       "4       [[Electronics, GPS & Navigation, Vehicle GPS, ...   \n",
       "...                                                   ...   \n",
       "498191  [[Electronics, GPS & Navigation, GPS System Ac...   \n",
       "498192  [[Electronics, Computers & Accessories, Cables...   \n",
       "498193  [[Electronics, Computers & Accessories, Cables...   \n",
       "498194  [[Electronics, Computers & Accessories, Cables...   \n",
       "498195  [[Electronics, Computers & Accessories, Cables...   \n",
       "\n",
       "                                                    title   price  \\\n",
       "0       Kelby Training DVD: Mastering Blend Modes in A...     NaN   \n",
       "1       Kelby Training DVD: Adobe Photoshop CS5 Crash ...     NaN   \n",
       "2                         Digital Organizer and Messenger    8.15   \n",
       "3       CLIKR-5 Time Warner Cable Remote Control UR5U-...   23.36   \n",
       "4       Rand McNally 528881469 7-inch Intelliroute TND...  299.99   \n",
       "...                                                   ...     ...   \n",
       "498191                                  Suction Cup Mount   21.99   \n",
       "498192                     Parallel PCMCIA Card 1PORT Epp   23.99   \n",
       "498193         C2G / Cables to Go 5M Ultima USB 2.0 Cable   18.91   \n",
       "498194                          Underdesk Keyboard Drawer   25.54   \n",
       "498195                        USB To R232 Converter Cable   62.31   \n",
       "\n",
       "                      salesRank  \\\n",
       "0                           NaN   \n",
       "1                           NaN   \n",
       "2       {'Electronics': 144944}   \n",
       "3                           NaN   \n",
       "4                           NaN   \n",
       "...                         ...   \n",
       "498191                      NaN   \n",
       "498192                      NaN   \n",
       "498193                      NaN   \n",
       "498194                      NaN   \n",
       "498195                      NaN   \n",
       "\n",
       "                                                  related     brand  \n",
       "0                                                     NaN       NaN  \n",
       "1                                                     NaN       NaN  \n",
       "2       {'also_viewed': ['0545016266', 'B009ECM8QY', '...       NaN  \n",
       "3       {'also_viewed': ['B001KC08A4', 'B00KUL8O0W', '...       NaN  \n",
       "4       {'also_viewed': ['B006ZOI9OY', 'B00C7FKT2A', '...       NaN  \n",
       "...                                                   ...       ...  \n",
       "498191              {'buy_after_viewing': ['B000EPFCC2']}    Garmin  \n",
       "498192  {'also_bought': ['B000SR2H4W', 'B001Q7X0W6'], ...       NaN  \n",
       "498193  {'bought_together': ['B0002D6QJO'], 'buy_after...       C2G  \n",
       "498194  {'also_viewed': ['B0002LD0ZY', 'B0002LCZP0', '...  Fellowes  \n",
       "498195  {'also_viewed': ['B0007T27H8', 'B00425S1H8', '...    Garmin  \n",
       "\n",
       "[498196 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the overall product meta dataset\n",
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out product meta dataset\n",
    "meta_df = meta_df[meta_df['asin'].isin(reviews_df['asin'].unique())]\n",
    "meta_df = meta_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>imUrl</th>\n",
       "      <th>description</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>related</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0972683275</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41hYJ9Mw...</td>\n",
       "      <td>The VideoSecu TV mount is a mounting solution ...</td>\n",
       "      <td>[[Electronics, Accessories &amp; Supplies, Audio &amp;...</td>\n",
       "      <td>VideoSecu 24&amp;quot; Long Arm TV Wall Mount Low ...</td>\n",
       "      <td>29.99</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'also_bought': ['B000X3KOD2', 'B0074FGR74', '...</td>\n",
       "      <td>VideoSecu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400532620</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/519ca3cu...</td>\n",
       "      <td>Barnes &amp; Noble Nook eReader - no 3GMeet nook. ...</td>\n",
       "      <td>[[Electronics, eBook Readers &amp; Accessories]]</td>\n",
       "      <td>Barnes &amp;amp; Noble Nook eReader - no 3G</td>\n",
       "      <td>74.95</td>\n",
       "      <td>{'Electronics': 23071}</td>\n",
       "      <td>{'also_bought': ['B0035CLBT4', 'B004X18N24', '...</td>\n",
       "      <td>Barnes &amp;amp; Noble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140053271X</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51jat7CV...</td>\n",
       "      <td>Barnes &amp; Noble Nook Simple Touch Wi-Fi ReaderI...</td>\n",
       "      <td>[[Electronics, eBook Readers &amp; Accessories, eB...</td>\n",
       "      <td>Barnes &amp;amp; Noble Nook Simple Touch eBook Rea...</td>\n",
       "      <td>79.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'also_bought': ['B007UXNHNM', 'B007UXNHGY', '...</td>\n",
       "      <td>Barnes &amp;amp; Noble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1400532736</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/413fSdlM...</td>\n",
       "      <td>The NOOK Simple Touch eReader allows you to re...</td>\n",
       "      <td>[[Electronics, eBook Readers &amp; Accessories, eB...</td>\n",
       "      <td>Nook Simple Touch eReader</td>\n",
       "      <td>62.99</td>\n",
       "      <td>{'Electronics': 4945}</td>\n",
       "      <td>{'also_bought': ['B0055ZDRI2', 'B007UXNHGY', '...</td>\n",
       "      <td>Barnes &amp;amp; Noble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400698987</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51lnBzuR...</td>\n",
       "      <td>The Nook HD Tablet has an amazing combination ...</td>\n",
       "      <td>[[Electronics, Computers &amp; Accessories, Tablets]]</td>\n",
       "      <td>Nook HD 7&amp;quot; 8GB Tablet</td>\n",
       "      <td>158.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'also_bought': ['B00AAKLIIS', 'B00E9IAQ1C', '...</td>\n",
       "      <td>Barnes &amp;amp; Noble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44113</th>\n",
       "      <td>B00KSLCU72</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41wlybKm...</td>\n",
       "      <td>FosPower FUSE Universal World Travel USB AC Ad...</td>\n",
       "      <td>[[Electronics, Accessories &amp; Supplies, Batteri...</td>\n",
       "      <td>FosPower FUSE World-Wide Universal AC Adapter ...</td>\n",
       "      <td>7.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'also_bought': ['B00JJOEV9Y', 'B00L8HA5L8', '...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44114</th>\n",
       "      <td>B00KVNY2KA</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/417lJxa9...</td>\n",
       "      <td>The Satechi Spectrum Mouse Wired Optical Mouse...</td>\n",
       "      <td>[[Electronics, Computers &amp; Accessories, Cables...</td>\n",
       "      <td>Satechi Spectrum Mouse Wired Optical Mouse (Si...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'also_viewed': ['B00LIBH4YK', 'B00CJKW4WQ', '...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44115</th>\n",
       "      <td>B00KWHMR6G</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41phatTV...</td>\n",
       "      <td></td>\n",
       "      <td>[[Electronics, Computers &amp; Accessories, Networ...</td>\n",
       "      <td>NETGEAR AC3200 Nighthawk X6 Tri-Band WiFi Rout...</td>\n",
       "      <td>299.99</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'also_bought': ['B008I64O78', 'B008I64EKA', '...</td>\n",
       "      <td>Netgear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44116</th>\n",
       "      <td>B00KYMCJF8</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/518oN4Vz...</td>\n",
       "      <td>Omaker-Open your mind,we are the makerOmaker B...</td>\n",
       "      <td>[[Electronics, Portable Audio &amp; Video, MP3 Pla...</td>\n",
       "      <td>Omaker M3-Outdoor Sport Rugged Square Design S...</td>\n",
       "      <td>29.99</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'also_bought': ['B00J0CVVGQ', 'B00KQCJ0CG', '...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44117</th>\n",
       "      <td>B00L3YHF6O</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41SBx7QY...</td>\n",
       "      <td>Mind-Shattering Performance, Precision-Tuned F...</td>\n",
       "      <td>[[Electronics, Home Audio, Stereo Components, ...</td>\n",
       "      <td>NEW! Creative Sound Blaster Roar: Portable NFC...</td>\n",
       "      <td>149.99</td>\n",
       "      <td>{'Cell Phones &amp; Accessories': 131}</td>\n",
       "      <td>{'also_bought': ['B00LBNW2TC', 'B00L8I6SFY', '...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44118 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin                                              imUrl  \\\n",
       "0      0972683275  http://ecx.images-amazon.com/images/I/41hYJ9Mw...   \n",
       "1      1400532620  http://ecx.images-amazon.com/images/I/519ca3cu...   \n",
       "2      140053271X  http://ecx.images-amazon.com/images/I/51jat7CV...   \n",
       "3      1400532736  http://ecx.images-amazon.com/images/I/413fSdlM...   \n",
       "4      1400698987  http://ecx.images-amazon.com/images/I/51lnBzuR...   \n",
       "...           ...                                                ...   \n",
       "44113  B00KSLCU72  http://ecx.images-amazon.com/images/I/41wlybKm...   \n",
       "44114  B00KVNY2KA  http://ecx.images-amazon.com/images/I/417lJxa9...   \n",
       "44115  B00KWHMR6G  http://ecx.images-amazon.com/images/I/41phatTV...   \n",
       "44116  B00KYMCJF8  http://ecx.images-amazon.com/images/I/518oN4Vz...   \n",
       "44117  B00L3YHF6O  http://ecx.images-amazon.com/images/I/41SBx7QY...   \n",
       "\n",
       "                                             description  \\\n",
       "0      The VideoSecu TV mount is a mounting solution ...   \n",
       "1      Barnes & Noble Nook eReader - no 3GMeet nook. ...   \n",
       "2      Barnes & Noble Nook Simple Touch Wi-Fi ReaderI...   \n",
       "3      The NOOK Simple Touch eReader allows you to re...   \n",
       "4      The Nook HD Tablet has an amazing combination ...   \n",
       "...                                                  ...   \n",
       "44113  FosPower FUSE Universal World Travel USB AC Ad...   \n",
       "44114  The Satechi Spectrum Mouse Wired Optical Mouse...   \n",
       "44115                                                      \n",
       "44116  Omaker-Open your mind,we are the makerOmaker B...   \n",
       "44117  Mind-Shattering Performance, Precision-Tuned F...   \n",
       "\n",
       "                                              categories  \\\n",
       "0      [[Electronics, Accessories & Supplies, Audio &...   \n",
       "1           [[Electronics, eBook Readers & Accessories]]   \n",
       "2      [[Electronics, eBook Readers & Accessories, eB...   \n",
       "3      [[Electronics, eBook Readers & Accessories, eB...   \n",
       "4      [[Electronics, Computers & Accessories, Tablets]]   \n",
       "...                                                  ...   \n",
       "44113  [[Electronics, Accessories & Supplies, Batteri...   \n",
       "44114  [[Electronics, Computers & Accessories, Cables...   \n",
       "44115  [[Electronics, Computers & Accessories, Networ...   \n",
       "44116  [[Electronics, Portable Audio & Video, MP3 Pla...   \n",
       "44117  [[Electronics, Home Audio, Stereo Components, ...   \n",
       "\n",
       "                                                   title   price  \\\n",
       "0      VideoSecu 24&quot; Long Arm TV Wall Mount Low ...   29.99   \n",
       "1                Barnes &amp; Noble Nook eReader - no 3G   74.95   \n",
       "2      Barnes &amp; Noble Nook Simple Touch eBook Rea...   79.49   \n",
       "3                              Nook Simple Touch eReader   62.99   \n",
       "4                             Nook HD 7&quot; 8GB Tablet  158.99   \n",
       "...                                                  ...     ...   \n",
       "44113  FosPower FUSE World-Wide Universal AC Adapter ...    7.99   \n",
       "44114  Satechi Spectrum Mouse Wired Optical Mouse (Si...   24.99   \n",
       "44115  NETGEAR AC3200 Nighthawk X6 Tri-Band WiFi Rout...  299.99   \n",
       "44116  Omaker M3-Outdoor Sport Rugged Square Design S...   29.99   \n",
       "44117  NEW! Creative Sound Blaster Roar: Portable NFC...  149.99   \n",
       "\n",
       "                                salesRank  \\\n",
       "0                                      {}   \n",
       "1                  {'Electronics': 23071}   \n",
       "2                                     NaN   \n",
       "3                   {'Electronics': 4945}   \n",
       "4                                     NaN   \n",
       "...                                   ...   \n",
       "44113                                 NaN   \n",
       "44114                                 NaN   \n",
       "44115                                  {}   \n",
       "44116                                  {}   \n",
       "44117  {'Cell Phones & Accessories': 131}   \n",
       "\n",
       "                                                 related               brand  \n",
       "0      {'also_bought': ['B000X3KOD2', 'B0074FGR74', '...           VideoSecu  \n",
       "1      {'also_bought': ['B0035CLBT4', 'B004X18N24', '...  Barnes &amp; Noble  \n",
       "2      {'also_bought': ['B007UXNHNM', 'B007UXNHGY', '...  Barnes &amp; Noble  \n",
       "3      {'also_bought': ['B0055ZDRI2', 'B007UXNHGY', '...  Barnes &amp; Noble  \n",
       "4      {'also_bought': ['B00AAKLIIS', 'B00E9IAQ1C', '...  Barnes &amp; Noble  \n",
       "...                                                  ...                 ...  \n",
       "44113  {'also_bought': ['B00JJOEV9Y', 'B00L8HA5L8', '...                 NaN  \n",
       "44114  {'also_viewed': ['B00LIBH4YK', 'B00CJKW4WQ', '...                 NaN  \n",
       "44115  {'also_bought': ['B008I64O78', 'B008I64EKA', '...             Netgear  \n",
       "44116  {'also_bought': ['B00J0CVVGQ', 'B00KQCJ0CG', '...                 NaN  \n",
       "44117  {'also_bought': ['B00LBNW2TC', 'B00L8I6SFY', '...                 NaN  \n",
       "\n",
       "[44118 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the object `meta_df` to the open file object `meta.pkl`\n",
    "with open('./data/meta.pkl', 'wb') as f:\n",
    "    pickle.dump(meta_df, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A000715434M800HLCENK9</td>\n",
       "      <td>B000UYYZ0M</td>\n",
       "      <td>DP</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>So the screen itself is OK. it is an actual sc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Spring is not strong</td>\n",
       "      <td>1400457600</td>\n",
       "      <td>05 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A000715434M800HLCENK9</td>\n",
       "      <td>B001EHAI6Y</td>\n",
       "      <td>DP</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I had a complicated set up for my screen. I ne...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Exactly what i wanted</td>\n",
       "      <td>1400457600</td>\n",
       "      <td>05 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A000715434M800HLCENK9</td>\n",
       "      <td>B003AFONFU</td>\n",
       "      <td>DP</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>The mount is good if you account for the play ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>beware of the play</td>\n",
       "      <td>1400457600</td>\n",
       "      <td>05 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A000715434M800HLCENK9</td>\n",
       "      <td>B003ES5ZUU</td>\n",
       "      <td>DP</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>For some reason this product doesnt work that ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Not great with Apple TV</td>\n",
       "      <td>1400457600</td>\n",
       "      <td>05 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A000715434M800HLCENK9</td>\n",
       "      <td>B00HMZG3YS</td>\n",
       "      <td>DP</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Great box Exactly what i needed. it isnt water...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Very good</td>\n",
       "      <td>1400457600</td>\n",
       "      <td>05 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168576</th>\n",
       "      <td>A1DJR7B306SJIY</td>\n",
       "      <td>B0026RHPSU</td>\n",
       "      <td>James \"Jim\"</td>\n",
       "      <td>[8, 13]</td>\n",
       "      <td>In my opinion this is a very poor choice of wa...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Why buy an expensive dock?</td>\n",
       "      <td>1295308800</td>\n",
       "      <td>01 18, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168577</th>\n",
       "      <td>A1DJR7B306SJIY</td>\n",
       "      <td>B0031QNP8O</td>\n",
       "      <td>James \"Jim\"</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>I had a Garmin Trek prior to buying this. I wa...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Difficult to operate for the neophyte</td>\n",
       "      <td>1381622400</td>\n",
       "      <td>10 13, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168578</th>\n",
       "      <td>A1DJR7B306SJIY</td>\n",
       "      <td>B003BEDQR6</td>\n",
       "      <td>James \"Jim\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>For the price, this is a great system. The fac...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good sound</td>\n",
       "      <td>1358640000</td>\n",
       "      <td>01 20, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168579</th>\n",
       "      <td>A1DJR7B306SJIY</td>\n",
       "      <td>B0097BEF1S</td>\n",
       "      <td>James \"Jim\"</td>\n",
       "      <td>[7, 27]</td>\n",
       "      <td>The main gripes I have about this product is n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Apple is deceitful</td>\n",
       "      <td>1368662400</td>\n",
       "      <td>05 16, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168580</th>\n",
       "      <td>A1DJR7B306SJIY</td>\n",
       "      <td>B00INNP5VU</td>\n",
       "      <td>James \"Jim\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>It sure has a lot of free things on it. I'm no...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Nice</td>\n",
       "      <td>1396569600</td>\n",
       "      <td>04 4, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168581 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   reviewerID        asin reviewerName  helpful  \\\n",
       "0       A000715434M800HLCENK9  B000UYYZ0M           DP   [0, 0]   \n",
       "1       A000715434M800HLCENK9  B001EHAI6Y           DP   [0, 0]   \n",
       "2       A000715434M800HLCENK9  B003AFONFU           DP   [1, 1]   \n",
       "3       A000715434M800HLCENK9  B003ES5ZUU           DP   [0, 0]   \n",
       "4       A000715434M800HLCENK9  B00HMZG3YS           DP   [0, 0]   \n",
       "...                       ...         ...          ...      ...   \n",
       "168576         A1DJR7B306SJIY  B0026RHPSU  James \"Jim\"  [8, 13]   \n",
       "168577         A1DJR7B306SJIY  B0031QNP8O  James \"Jim\"   [1, 3]   \n",
       "168578         A1DJR7B306SJIY  B003BEDQR6  James \"Jim\"   [0, 0]   \n",
       "168579         A1DJR7B306SJIY  B0097BEF1S  James \"Jim\"  [7, 27]   \n",
       "168580         A1DJR7B306SJIY  B00INNP5VU  James \"Jim\"   [0, 0]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "0       So the screen itself is OK. it is an actual sc...      1.0   \n",
       "1       I had a complicated set up for my screen. I ne...      5.0   \n",
       "2       The mount is good if you account for the play ...      3.0   \n",
       "3       For some reason this product doesnt work that ...      2.0   \n",
       "4       Great box Exactly what i needed. it isnt water...      5.0   \n",
       "...                                                   ...      ...   \n",
       "168576  In my opinion this is a very poor choice of wa...      1.0   \n",
       "168577  I had a Garmin Trek prior to buying this. I wa...      2.0   \n",
       "168578  For the price, this is a great system. The fac...      4.0   \n",
       "168579  The main gripes I have about this product is n...      1.0   \n",
       "168580  It sure has a lot of free things on it. I'm no...      5.0   \n",
       "\n",
       "                                      summary  unixReviewTime   reviewTime  \n",
       "0                        Spring is not strong      1400457600  05 19, 2014  \n",
       "1                       Exactly what i wanted      1400457600  05 19, 2014  \n",
       "2                          beware of the play      1400457600  05 19, 2014  \n",
       "3                     Not great with Apple TV      1400457600  05 19, 2014  \n",
       "4                                   Very good      1400457600  05 19, 2014  \n",
       "...                                       ...             ...          ...  \n",
       "168576             Why buy an expensive dock?      1295308800  01 18, 2011  \n",
       "168577  Difficult to operate for the neophyte      1381622400  10 13, 2013  \n",
       "168578                             Good sound      1358640000  01 20, 2013  \n",
       "168579                     Apple is deceitful      1368662400  05 16, 2013  \n",
       "168580                                   Nice      1396569600   04 4, 2014  \n",
       "\n",
       "[168581 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out reviews dataset\n",
    "reviews_df = reviews_df[reviews_df['asin'].isin(meta_df['asin'].unique())]\n",
    "reviews_df = reviews_df.reset_index(drop=True)\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A000715434M800HLCENK9</td>\n",
       "      <td>B000UYYZ0M</td>\n",
       "      <td>1400457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A000715434M800HLCENK9</td>\n",
       "      <td>B001EHAI6Y</td>\n",
       "      <td>1400457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A000715434M800HLCENK9</td>\n",
       "      <td>B003AFONFU</td>\n",
       "      <td>1400457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A000715434M800HLCENK9</td>\n",
       "      <td>B003ES5ZUU</td>\n",
       "      <td>1400457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A000715434M800HLCENK9</td>\n",
       "      <td>B00HMZG3YS</td>\n",
       "      <td>1400457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168576</th>\n",
       "      <td>A1DJR7B306SJIY</td>\n",
       "      <td>B0026RHPSU</td>\n",
       "      <td>1295308800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168577</th>\n",
       "      <td>A1DJR7B306SJIY</td>\n",
       "      <td>B0031QNP8O</td>\n",
       "      <td>1381622400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168578</th>\n",
       "      <td>A1DJR7B306SJIY</td>\n",
       "      <td>B003BEDQR6</td>\n",
       "      <td>1358640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168579</th>\n",
       "      <td>A1DJR7B306SJIY</td>\n",
       "      <td>B0097BEF1S</td>\n",
       "      <td>1368662400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168580</th>\n",
       "      <td>A1DJR7B306SJIY</td>\n",
       "      <td>B00INNP5VU</td>\n",
       "      <td>1396569600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168581 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   reviewerID        asin  unixReviewTime\n",
       "0       A000715434M800HLCENK9  B000UYYZ0M      1400457600\n",
       "1       A000715434M800HLCENK9  B001EHAI6Y      1400457600\n",
       "2       A000715434M800HLCENK9  B003AFONFU      1400457600\n",
       "3       A000715434M800HLCENK9  B003ES5ZUU      1400457600\n",
       "4       A000715434M800HLCENK9  B00HMZG3YS      1400457600\n",
       "...                       ...         ...             ...\n",
       "168576         A1DJR7B306SJIY  B0026RHPSU      1295308800\n",
       "168577         A1DJR7B306SJIY  B0031QNP8O      1381622400\n",
       "168578         A1DJR7B306SJIY  B003BEDQR6      1358640000\n",
       "168579         A1DJR7B306SJIY  B0097BEF1S      1368662400\n",
       "168580         A1DJR7B306SJIY  B00INNP5VU      1396569600\n",
       "\n",
       "[168581 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select useful features\n",
    "reviews_df = reviews_df[['reviewerID', 'asin', 'unixReviewTime']]\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0972683275</td>\n",
       "      <td>[[Electronics, Accessories &amp; Supplies, Audio &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400532620</td>\n",
       "      <td>[[Electronics, eBook Readers &amp; Accessories]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140053271X</td>\n",
       "      <td>[[Electronics, eBook Readers &amp; Accessories, eB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1400532736</td>\n",
       "      <td>[[Electronics, eBook Readers &amp; Accessories, eB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400698987</td>\n",
       "      <td>[[Electronics, Computers &amp; Accessories, Tablets]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44113</th>\n",
       "      <td>B00KSLCU72</td>\n",
       "      <td>[[Electronics, Accessories &amp; Supplies, Batteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44114</th>\n",
       "      <td>B00KVNY2KA</td>\n",
       "      <td>[[Electronics, Computers &amp; Accessories, Cables...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44115</th>\n",
       "      <td>B00KWHMR6G</td>\n",
       "      <td>[[Electronics, Computers &amp; Accessories, Networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44116</th>\n",
       "      <td>B00KYMCJF8</td>\n",
       "      <td>[[Electronics, Portable Audio &amp; Video, MP3 Pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44117</th>\n",
       "      <td>B00L3YHF6O</td>\n",
       "      <td>[[Electronics, Home Audio, Stereo Components, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44118 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin                                         categories\n",
       "0      0972683275  [[Electronics, Accessories & Supplies, Audio &...\n",
       "1      1400532620       [[Electronics, eBook Readers & Accessories]]\n",
       "2      140053271X  [[Electronics, eBook Readers & Accessories, eB...\n",
       "3      1400532736  [[Electronics, eBook Readers & Accessories, eB...\n",
       "4      1400698987  [[Electronics, Computers & Accessories, Tablets]]\n",
       "...           ...                                                ...\n",
       "44113  B00KSLCU72  [[Electronics, Accessories & Supplies, Batteri...\n",
       "44114  B00KVNY2KA  [[Electronics, Computers & Accessories, Cables...\n",
       "44115  B00KWHMR6G  [[Electronics, Computers & Accessories, Networ...\n",
       "44116  B00KYMCJF8  [[Electronics, Portable Audio & Video, MP3 Pla...\n",
       "44117  B00L3YHF6O  [[Electronics, Home Audio, Stereo Components, ...\n",
       "\n",
       "[44118 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Electronics: 63001 rows × 2 columns\n",
    "# select useful features\n",
    "if 'category' in meta_df.columns:\n",
    "    meta_df = meta_df[['asin', 'category']]\n",
    "    meta_df['category'] = meta_df['category'].apply(lambda x: ['Magazine Subscriptions'] if len(x)==0 else x)\n",
    "else:\n",
    "    # Electronics\n",
    "    meta_df = meta_df[['asin', 'categories']]\n",
    "\n",
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-e90f48238181>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meta_df['categories'] = meta_df['categories'].map(lambda x: x[-1][-1])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0972683275</td>\n",
       "      <td>TV Ceiling &amp; Wall Mounts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400532620</td>\n",
       "      <td>eBook Readers &amp; Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140053271X</td>\n",
       "      <td>eBook Readers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1400532736</td>\n",
       "      <td>eBook Readers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400698987</td>\n",
       "      <td>Tablets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44113</th>\n",
       "      <td>B00KSLCU72</td>\n",
       "      <td>AC Adapters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44114</th>\n",
       "      <td>B00KVNY2KA</td>\n",
       "      <td>Mice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44115</th>\n",
       "      <td>B00KWHMR6G</td>\n",
       "      <td>Wireless Access Points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44116</th>\n",
       "      <td>B00KYMCJF8</td>\n",
       "      <td>MP3 Players</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44117</th>\n",
       "      <td>B00L3YHF6O</td>\n",
       "      <td>Speaker Systems</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44118 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin                   categories\n",
       "0      0972683275     TV Ceiling & Wall Mounts\n",
       "1      1400532620  eBook Readers & Accessories\n",
       "2      140053271X                eBook Readers\n",
       "3      1400532736                eBook Readers\n",
       "4      1400698987                      Tablets\n",
       "...           ...                          ...\n",
       "44113  B00KSLCU72                  AC Adapters\n",
       "44114  B00KVNY2KA                         Mice\n",
       "44115  B00KWHMR6G       Wireless Access Points\n",
       "44116  B00KYMCJF8                  MP3 Players\n",
       "44117  B00L3YHF6O              Speaker Systems\n",
       "\n",
       "[44118 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Electronics: 63001 rows × 2 columns\n",
    "# only one category\n",
    "if 'category' in meta_df.columns:\n",
    "    meta_df['category'] = meta_df['category'].map(lambda x: x[-1])\n",
    "else:\n",
    "    meta_df['categories'] = meta_df['categories'].map(lambda x: x[-1][-1])\n",
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_map(df, col_name):\n",
    "    key = sorted(df[col_name].unique().tolist())\n",
    "    m = dict(zip(key, range(len(key))))\n",
    "    df[col_name] = df[col_name].map(lambda x: m[x])\n",
    "    return m, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-e50a75d142fb>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_name] = df[col_name].map(lambda x: m[x])\n"
     ]
    }
   ],
   "source": [
    "asin_map, asin_key = build_map(meta_df, 'asin')\n",
    "if 'category' in meta_df.columns:\n",
    "    cate_map, cate_key = build_map(meta_df, 'category')\n",
    "else:\n",
    "    cate_map, cate_key = build_map(meta_df, 'categories')\n",
    "revi_map, revi_key = build_map(reviews_df, 'reviewerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_count: 19240\titem_count: 44118\tcate_count: 766\texample_count: 168581\n"
     ]
    }
   ],
   "source": [
    "user_count, item_count, cate_count, example_count =\\\n",
    "    len(revi_map), len(asin_map), len(cate_map), reviews_df.shape[0]\n",
    "print('user_count: %d\\titem_count: %d\\tcate_count: %d\\texample_count: %d' %\n",
    "      (user_count, item_count, cate_count, example_count))\n",
    "# Electronics: user_count: 192403\titem_count: 63001\tcate_count: 801\texample_count: 1689188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44113</th>\n",
       "      <td>44113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44114</th>\n",
       "      <td>44114</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44115</th>\n",
       "      <td>44115</td>\n",
       "      <td>757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44116</th>\n",
       "      <td>44116</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44117</th>\n",
       "      <td>44117</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44118 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        asin  categories\n",
       "0          0         675\n",
       "1          1         682\n",
       "2          2         682\n",
       "3          3         763\n",
       "4          4         764\n",
       "...      ...         ...\n",
       "44113  44113           1\n",
       "44114  44114         462\n",
       "44115  44115         757\n",
       "44116  44116         443\n",
       "44117  44117         644\n",
       "\n",
       "[44118 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Electronics: 63001 rows × 2 columns\n",
    "meta_df = meta_df.sort_values('asin')\n",
    "meta_df = meta_df.reset_index(drop=True)\n",
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-0c167f08e44d>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews_df['asin'] = reviews_df['asin'].map(lambda x: asin_map[x])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9123</td>\n",
       "      <td>1400457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>12521</td>\n",
       "      <td>1400457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>19848</td>\n",
       "      <td>1400457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20498</td>\n",
       "      <td>1400457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>43644</td>\n",
       "      <td>1400457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168576</th>\n",
       "      <td>19239</td>\n",
       "      <td>37249</td>\n",
       "      <td>1368662400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168577</th>\n",
       "      <td>19239</td>\n",
       "      <td>10115</td>\n",
       "      <td>1374796800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168578</th>\n",
       "      <td>19239</td>\n",
       "      <td>12317</td>\n",
       "      <td>1374796800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168579</th>\n",
       "      <td>19239</td>\n",
       "      <td>18643</td>\n",
       "      <td>1381622400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168580</th>\n",
       "      <td>19239</td>\n",
       "      <td>43897</td>\n",
       "      <td>1396569600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168581 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        reviewerID   asin  unixReviewTime\n",
       "0                0   9123      1400457600\n",
       "1                0  12521      1400457600\n",
       "2                0  19848      1400457600\n",
       "3                0  20498      1400457600\n",
       "4                0  43644      1400457600\n",
       "...            ...    ...             ...\n",
       "168576       19239  37249      1368662400\n",
       "168577       19239  10115      1374796800\n",
       "168578       19239  12317      1374796800\n",
       "168579       19239  18643      1381622400\n",
       "168580       19239  43897      1396569600\n",
       "\n",
       "[168581 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Electronics: 1689188 rows × 3 columns\n",
    "reviews_df['asin'] = reviews_df['asin'].map(lambda x: asin_map[x])\n",
    "reviews_df = reviews_df.sort_values(['reviewerID', 'unixReviewTime'])\n",
    "reviews_df = reviews_df.reset_index(drop=True)\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_list = [meta_df['categories'][i] for i in range(len(asin_map))]\n",
    "cate_list = np.array(cate_list, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the data to the open file object `remap.pkl`\n",
    "with open('./data/remap.pkl', 'wb') as f:\n",
    "    pickle.dump(reviews_df, f, pickle.HIGHEST_PROTOCOL) # uid, iid\n",
    "    pickle.dump(cate_list, f, pickle.HIGHEST_PROTOCOL) # cid of iid line\n",
    "    pickle.dump((user_count, item_count, cate_count, example_count), f, pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump((asin_key, cate_key, revi_key), f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "train_set = []\n",
    "test_set = []\n",
    "\n",
    "for reviewerID, hist in reviews_df.groupby('reviewerID'):\n",
    "    pos_list = hist['asin'].tolist()\n",
    "    neg_list = []\n",
    "    for _ in range(len(pos_list)):\n",
    "        neg = pos_list[0]\n",
    "        while neg in pos_list + neg_list:\n",
    "            neg = random.randint(0, item_count - 1)\n",
    "        neg_list.append(neg)\n",
    "\n",
    "    for i in range(1, len(pos_list) - 1):\n",
    "        hist = pos_list[:i]\n",
    "        train_set.append((reviewerID, hist, pos_list[i], 1))\n",
    "        train_set.append((reviewerID, hist, neg_list[i], 0))\n",
    "    \n",
    "    label = (pos_list[-1], neg_list[-1])\n",
    "    test_set.append((reviewerID, hist, label))\n",
    "\n",
    "random.shuffle(train_set)\n",
    "random.shuffle(test_set)\n",
    "\n",
    "assert len(test_set) == user_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9184, [9519, 8918, 14514, 21572, 22732], 140, 0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260202"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18882, [12289, 25828, 27089, 27393], (31900, 20416))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19240"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the data to the open file object `dataset.pkl`\n",
    "with open('./data/dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(train_set, f, pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump(test_set, f, pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump(cate_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump((user_count, item_count, cate_count), f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.dataset_dir+'dataset.pkl', 'rb') as f:\n",
    "    train_set = pickle.load(f, encoding='latin1')\n",
    "    test_set = pickle.load(f, encoding='latin1')\n",
    "    cate_list = pickle.load(f, encoding='latin1')\n",
    "    cate_list = tf.convert_to_tensor(cate_list, dtype=tf.int64)\n",
    "    user_count, item_count, cate_count = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, batch_size, data):\n",
    "        self.batch_size = batch_size\n",
    "        self.data = data\n",
    "        self.epoch_size = len(self.data) // self.batch_size\n",
    "        if self.epoch_size * self.batch_size < len(self.data):\n",
    "            self.epoch_size += 1\n",
    "        self.i = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.i == self.epoch_size:\n",
    "            raise StopIteration\n",
    "        ts = self.data[self.i * self.batch_size : min((self.i+1) * self.batch_size,\n",
    "                                                      len(self.data))]\n",
    "        self.i += 1\n",
    "\n",
    "        u, i, y, sl = [], [], [], []\n",
    "        for t in ts:\n",
    "            u.append(t[0])\n",
    "            i.append(t[2])\n",
    "            y.append(t[3])\n",
    "            sl.append(len(t[1]))\n",
    "        max_sl = max(sl)\n",
    "\n",
    "        hist_i = np.zeros([len(ts), max_sl], np.int64)\n",
    "\n",
    "        k = 0\n",
    "        for t in ts:\n",
    "            for l in range(len(t[1])):\n",
    "                hist_i[k][l] = t[1][l]\n",
    "            k += 1\n",
    "\n",
    "        return tf.convert_to_tensor(u), tf.convert_to_tensor(i), \\\n",
    "               tf.convert_to_tensor(y), tf.convert_to_tensor(hist_i), \\\n",
    "               sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderTest:\n",
    "    def __init__(self, batch_size, data):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.data = data\n",
    "        self.epoch_size = len(self.data) // self.batch_size\n",
    "        if self.epoch_size * self.batch_size < len(self.data):\n",
    "            self.epoch_size += 1\n",
    "        self.i = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "\n",
    "        if self.i == self.epoch_size:\n",
    "            raise StopIteration\n",
    "\n",
    "        ts = self.data[self.i * self.batch_size : min((self.i+1) * self.batch_size,\n",
    "                                                      len(self.data))]\n",
    "        self.i += 1\n",
    "\n",
    "        u, i, j, sl = [], [], [], []\n",
    "        for t in ts:\n",
    "            u.append(t[0])\n",
    "            i.append(t[2][0])\n",
    "            j.append(t[2][1])\n",
    "            sl.append(len(t[1]))\n",
    "        max_sl = max(sl)\n",
    "\n",
    "        hist_i = np.zeros([len(ts), max_sl], np.int64)\n",
    "\n",
    "        k = 0\n",
    "        for t in ts:\n",
    "            for l in range(len(t[1])):\n",
    "                hist_i[k][l] = t[1][l]\n",
    "            k += 1\n",
    "\n",
    "        return tf.convert_to_tensor(u), tf.convert_to_tensor(i), \\\n",
    "               tf.convert_to_tensor(j), tf.convert_to_tensor(hist_i), \\\n",
    "               sl\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(train_batch_size, test_batch_size):\n",
    "    return DataLoader(train_batch_size, train_set), DataLoaderTest(test_batch_size, test_set), \\\n",
    "           user_count, item_count, cate_count, cate_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, keys_dim, dim_layers):\n",
    "        super(attention, self).__init__()\n",
    "        self.keys_dim = keys_dim\n",
    "\n",
    "        self.fc = tf.keras.Sequential()\n",
    "        for dim_layer in dim_layers[:-1]:\n",
    "            self.fc.add(nn.Dense(dim_layer, activation='sigmoid'))\n",
    "        self.fc.add(nn.Dense(dim_layers[-1], activation=None))\n",
    "\n",
    "    def call(self, queries, keys, keys_length):\n",
    "        queries = tf.tile(tf.expand_dims(queries, 1), [1, tf.shape(keys)[1], 1])\n",
    "        # outer product ?\n",
    "        din_all = tf.concat([queries, keys, queries-keys, queries*keys], axis=-1)\n",
    "        outputs = tf.transpose(self.fc(din_all), [0,2,1])\n",
    "\n",
    "        # Mask\n",
    "        key_masks = tf.sequence_mask(keys_length, max(keys_length), dtype=tf.bool)  # [B, T]\n",
    "        key_masks = tf.expand_dims(key_masks, 1)\n",
    "        paddings = tf.ones_like(outputs) * (-2 ** 32 + 1)\n",
    "        outputs = tf.where(key_masks, outputs, paddings)  # [B, 1, T]\n",
    "\n",
    "        # Scale\n",
    "        outputs = outputs / (self.keys_dim ** 0.5)\n",
    "\n",
    "        # Activation\n",
    "        outputs = tf.keras.activations.softmax(outputs, -1)  # [B, 1, T]\n",
    "\n",
    "        # Weighted sum\n",
    "        outputs = tf.squeeze(tf.matmul(outputs, keys))  # [B, H]\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dice(tf.keras.layers.Layer):\n",
    "    def __init__(self, feat_dim):\n",
    "        super(dice, self).__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.alphas= tf.Variable(tf.zeros([feat_dim]), dtype=tf.float32)\n",
    "        self.beta  = tf.Variable(tf.zeros([feat_dim]), dtype=tf.float32)\n",
    "\n",
    "        self.bn = tf.keras.layers.BatchNormalization(center=False, scale=False)\n",
    "\n",
    "    def call(self, _x, axis=-1, epsilon=0.000000001):\n",
    "\n",
    "        reduction_axes = list(range(len(_x.get_shape())))\n",
    "        del reduction_axes[axis]\n",
    "        broadcast_shape = [1] * len(_x.get_shape())\n",
    "        broadcast_shape[axis] = self.feat_dim\n",
    "\n",
    "        mean = tf.reduce_mean(_x, axis=reduction_axes)\n",
    "        brodcast_mean = tf.reshape(mean, broadcast_shape)\n",
    "        std = tf.reduce_mean(tf.square(_x - brodcast_mean) + epsilon, axis=reduction_axes)\n",
    "        std = tf.sqrt(std)\n",
    "        brodcast_std = tf.reshape(std, broadcast_shape)\n",
    "\n",
    "        x_normed = self.bn(_x)\n",
    "        x_p = tf.keras.activations.sigmoid(self.beta * x_normed)\n",
    "\n",
    "        return self.alphas * (1.0 - x_p) * _x + x_p * _x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parametric_relu(_x):\n",
    "    with tf.variable_scope(name_or_scope='', reuse=tf.AUTO_REUSE):\n",
    "        alphas = tf.get_variable('alpha', _x.get_shape()[-1],\n",
    "                                 initializer=tf.constant_initializer(0.0),\n",
    "                                 dtype=tf.float32)\n",
    "    pos = tf.nn.relu(_x)\n",
    "    neg = alphas * (_x - abs(_x)) * 0.5\n",
    "\n",
    "    return pos + neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base(tf.keras.Model):\n",
    "    def __init__(self, user_count, item_count, cate_count, cate_list,\n",
    "                       user_dim, item_dim, cate_dim,\n",
    "                       dim_layers):\n",
    "        super(Base, self).__init__()\n",
    "        self.item_dim = item_dim\n",
    "        self.cate_dim = cate_dim\n",
    "\n",
    "        self.user_emb = nn.Embedding(user_count, user_dim)\n",
    "        self.item_emb = nn.Embedding(item_count, item_dim)\n",
    "        self.cate_emb = nn.Embedding(cate_count, cate_dim)\n",
    "        self.item_bias= tf.Variable(tf.zeros([item_count]), trainable=True)\n",
    "        self.cate_list = cate_list\n",
    "\n",
    "        self.hist_bn = nn.BatchNormalization()\n",
    "        self.hist_fc = nn.Dense(item_dim+cate_dim)\n",
    "\n",
    "        self.fc = tf.keras.Sequential()\n",
    "        self.fc.add(nn.BatchNormalization())\n",
    "        for dim_layer in dim_layers[:-1]:\n",
    "            self.fc.add(nn.Dense(dim_layer, activation='sigmoid'))\n",
    "        self.fc.add(nn.Dense(dim_layers[-1], activation=None))\n",
    "\n",
    "    def get_emb(self, user, item, history):\n",
    "        user_emb = self.user_emb(user)\n",
    "\n",
    "        item_emb = self.item_emb(item)\n",
    "        item_cate_emb = self.cate_emb(tf.gather(self.cate_list, item))\n",
    "        item_join_emb = tf.concat([item_emb, item_cate_emb], -1)\n",
    "        item_bias= tf.gather(self.item_bias, item)\n",
    "\n",
    "        hist_emb = self.item_emb(history)\n",
    "        hist_cate_emb = self.cate_emb(tf.gather(self.cate_list, history))\n",
    "        hist_join_emb = tf.concat([hist_emb, hist_cate_emb], -1)\n",
    "\n",
    "        return user_emb, item_join_emb, item_bias, hist_join_emb\n",
    "\n",
    "    def call(self, user, item, history, length):\n",
    "        user_emb, item_join_emb, item_bias, hist_join_emb = self.get_emb(user, item, history)\n",
    "\n",
    "        hist_mask = tf.sequence_mask(length, max(length), dtype=tf.float32)\n",
    "        hist_mask = tf.tile(tf.expand_dims(hist_mask, -1), (1,1,self.item_dim+self.cate_dim))\n",
    "        hist_join_emb = tf.math.multiply(hist_join_emb, hist_mask)\n",
    "        hist_join_emb = tf.reduce_sum(hist_join_emb, 1)\n",
    "        hist_join_emb = tf.math.divide(hist_join_emb, tf.cast(tf.tile(tf.expand_dims(length, -1),\n",
    "                                                      [1,self.item_dim+self.cate_dim]), tf.float32))\n",
    "\n",
    "        hist_hid_emb = self.hist_fc(self.hist_bn(hist_join_emb))\n",
    "        join_emb = tf.concat([user_emb, item_join_emb, hist_hid_emb], -1)\n",
    "\n",
    "        output = tf.squeeze(self.fc(join_emb)) + item_bias\n",
    "        logit = tf.keras.activations.sigmoid(output)\n",
    "\n",
    "        return output, logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIN(Base):\n",
    "    def __init__(self, user_count, item_count, cate_count, cate_list,\n",
    "                       user_dim, item_dim, cate_dim,\n",
    "                       dim_layers):\n",
    "        super(DIN, self).__init__(user_count, item_count, cate_count, cate_list,\n",
    "                                  user_dim, item_dim, cate_dim,\n",
    "                                  dim_layers)\n",
    "\n",
    "        self.hist_at = attention(item_dim+cate_dim, dim_layers)\n",
    "\n",
    "        self.fc = tf.keras.Sequential()\n",
    "        self.fc.add(nn.BatchNormalization())\n",
    "        for dim_layer in dim_layers[:-1]:\n",
    "            self.fc.add(nn.Dense(dim_layer, activation=None))\n",
    "            self.fc.add(dice(dim_layer))\n",
    "        self.fc.add(nn.Dense(dim_layers[-1], activation=None))\n",
    "\n",
    "    def call(self, user, item, history, length):\n",
    "        user_emb, item_join_emb, item_bias, hist_join_emb = self.get_emb(user, item, history)\n",
    "\n",
    "        hist_attn_emb = self.hist_at(item_join_emb, hist_join_emb, length)\n",
    "        hist_attn_emb = self.hist_fc(self.hist_bn(hist_attn_emb))\n",
    "\n",
    "        join_emb = tf.concat([user_emb, item_join_emb, hist_attn_emb], -1)\n",
    "\n",
    "        output = tf.squeeze(self.fc(join_emb)) + item_bias\n",
    "        logit = tf.keras.activations.sigmoid(output)\n",
    "\n",
    "        return output, logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_auc(raw_arr):\n",
    "    \"\"\"Summary\n",
    "    Args:\n",
    "        raw_arr (TYPE): Description\n",
    "    Returns:\n",
    "        TYPE: Description\n",
    "    \"\"\"\n",
    "    # sort by pred value, from small to big\n",
    "    arr = sorted(raw_arr, key=lambda d:d[2])\n",
    "\n",
    "    auc = 0.0\n",
    "    fp1, tp1, fp2, tp2 = 0.0, 0.0, 0.0, 0.0\n",
    "    for record in arr:\n",
    "        fp2 += record[0] # noclick\n",
    "        tp2 += record[1] # click\n",
    "        auc += (fp2 - fp1) * (tp2 + tp1)\n",
    "        fp1, tp1 = fp2, tp2\n",
    "\n",
    "    # if all nonclick or click, disgard\n",
    "    threshold = len(arr) - 1e-3\n",
    "    if tp2 > threshold or fp2 > threshold:\n",
    "        return -0.5\n",
    "\n",
    "    if tp2 * fp2 > 0.0:  # normal auc\n",
    "        return (1.0 - auc / (2.0 * tp2 * fp2))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_arr(score_p, score_n):\n",
    "    score_arr = []\n",
    "    for s in score_p.numpy():\n",
    "        score_arr.append([0, 1, s])\n",
    "    for s in score_n.numpy():\n",
    "        score_arr.append([1, 0, s])\n",
    "    return score_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, test_data):\n",
    "    auc_sum = 0.0\n",
    "    score_arr = []\n",
    "    for u, i, j, hist_i, sl in test_data:\n",
    "        p_out, p_logit = model(u,i,hist_i,sl)\n",
    "        n_out, n_logit = model(u,j,hist_i,sl)\n",
    "        mf_auc = tf.reduce_sum(tf.cast(p_out>n_out, dtype=tf.float32))\n",
    "\n",
    "        score_arr += auc_arr(p_logit, n_logit)\n",
    "        auc_sum += mf_auc\n",
    "    test_gauc = auc_sum / len(test_data)\n",
    "    auc = calc_auc(score_arr)\n",
    "    return test_gauc, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a training data set of 260202 examples, a batch size of 32, and we have specified we want the algorithm to run for 10 epochs.\n",
    "\n",
    "Therefore, in each epoch, we have $260202/32 = 8132$ batches. Each batch gets passed through the algorithm, therefore we have 8132 iterations per epoch. Since we have specified 10 epochs, we have a total of $8132 \\times 10 = 81320$ iterations for the whole training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version of tensorflow: 2.7.0-rc0\n",
      "GPU Available:  []\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "'''\n",
    "0 = all messages are logged (default behavior)\n",
    "1 = INFO messages are not printed\n",
    "2 = INFO and WARNING messages are not printed\n",
    "3 = INFO, WARNING, and ERROR messages are not printed\n",
    "'''\n",
    "# Environment\n",
    "print(f\"Version of tensorflow: {tf.__version__}\")\n",
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load\n",
    "train_data, test_data, \\\n",
    "user_count, item_count, cate_count, \\\n",
    "cate_list = get_dataloader(args.train_batch_size, args.test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss, Optim\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=args.lr, momentum=0.0)\n",
    "loss_metric = tf.keras.metrics.Sum()\n",
    "auc_metric = tf.keras.metrics.AUC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Base(user_count, item_count, cate_count, cate_list,\n",
    "             args.user_dim, args.item_dim, args.cate_dim, args.dim_layers)\n",
    "\n",
    "# Board\n",
    "train_summary_writer = tf.summary.create_file_writer(args.log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train_one_step(u,i,y,hist_i,sl):\n",
    "    with tf.GradientTape() as tape:\n",
    "        output,_ = model(u,i,hist_i,sl)\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=output,\n",
    "                                                                      labels=tf.cast(y, dtype=tf.float32)))\n",
    "    gradient = tape.gradient(loss, model.trainable_variables)\n",
    "    clip_gradient, _ = tf.clip_by_global_norm(gradient, 5.0)\n",
    "    optimizer.apply_gradients(zip(clip_gradient, model.trainable_variables))\n",
    "\n",
    "    loss_metric(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(optimizer):\n",
    "    best_loss= 0.\n",
    "    best_auc = 0.\n",
    "    start_time = time.time()\n",
    "    # train 10 epochs\n",
    "    for epoch in range(args.epochs):\n",
    "        for step, (u, i, y, hist_i, sl) in enumerate(train_data, start=1):\n",
    "            train_one_step(u, i, y, hist_i, sl)\n",
    "\n",
    "            # print the result every 1000 steps\n",
    "            if step % args.print_step == 0:\n",
    "                test_gauc, auc = eval(model, test_data)\n",
    "                print('Epoch %d Global_step %d\\tTrain_loss: %.4f\\tEval_GAUC: %.4f\\tEval_AUC: %.4f' %\n",
    "                      (epoch, step, loss_metric.result() / args.print_step, test_gauc, auc))\n",
    "\n",
    "                # save the best model for now\n",
    "                if best_auc < test_gauc:\n",
    "                    best_loss= loss_metric.result() / args.print_step\n",
    "                    best_auc = test_gauc\n",
    "                    model.save_weights(args.model_path+'cp-%d.ckpt'%epoch)\n",
    "                loss_metric.reset_states()\n",
    "\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', best_loss, step=epoch)\n",
    "            tf.summary.scalar('test_gauc', best_auc, step=epoch)\n",
    "\n",
    "        loss_metric.reset_states()\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0)\n",
    "\n",
    "        print('Epoch %d DONE\\tCost time: %.2f' % (epoch, time.time()-start_time))\n",
    "    print('Best test_gauc: ', best_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Global_step 1000\tTrain_loss: 0.6952\tEval_GAUC: 0.6283\tEval_AUC: 0.6157\n",
      "Epoch 0 Global_step 2000\tTrain_loss: 0.6941\tEval_GAUC: 0.6603\tEval_AUC: 0.6497\n",
      "Epoch 0 Global_step 3000\tTrain_loss: 0.6934\tEval_GAUC: 0.6723\tEval_AUC: 0.6661\n",
      "Epoch 0 Global_step 4000\tTrain_loss: 0.6927\tEval_GAUC: 0.6781\tEval_AUC: 0.6762\n",
      "Epoch 0 Global_step 5000\tTrain_loss: 0.6914\tEval_GAUC: 0.6843\tEval_AUC: 0.6827\n",
      "Epoch 0 Global_step 6000\tTrain_loss: 0.6908\tEval_GAUC: 0.6873\tEval_AUC: 0.6856\n",
      "Epoch 0 Global_step 7000\tTrain_loss: 0.6900\tEval_GAUC: 0.6876\tEval_AUC: 0.6877\n",
      "Epoch 0 Global_step 8000\tTrain_loss: 0.6891\tEval_GAUC: 0.6904\tEval_AUC: 0.6898\n",
      "Epoch 0 DONE\tCost time: 237.80\n",
      "Epoch 1 Global_step 1000\tTrain_loss: 0.6876\tEval_GAUC: 0.6899\tEval_AUC: 0.6897\n",
      "Epoch 1 Global_step 2000\tTrain_loss: 0.6864\tEval_GAUC: 0.6913\tEval_AUC: 0.6899\n",
      "Epoch 1 Global_step 3000\tTrain_loss: 0.6861\tEval_GAUC: 0.6911\tEval_AUC: 0.6900\n",
      "Epoch 1 Global_step 4000\tTrain_loss: 0.6860\tEval_GAUC: 0.6904\tEval_AUC: 0.6902\n",
      "Epoch 1 Global_step 5000\tTrain_loss: 0.6844\tEval_GAUC: 0.6910\tEval_AUC: 0.6905\n",
      "Epoch 1 Global_step 6000\tTrain_loss: 0.6842\tEval_GAUC: 0.6904\tEval_AUC: 0.6903\n",
      "Epoch 1 Global_step 7000\tTrain_loss: 0.6837\tEval_GAUC: 0.6904\tEval_AUC: 0.6903\n",
      "Epoch 1 Global_step 8000\tTrain_loss: 0.6829\tEval_GAUC: 0.6898\tEval_AUC: 0.6908\n",
      "Epoch 1 DONE\tCost time: 466.92\n",
      "Epoch 2 Global_step 1000\tTrain_loss: 0.6817\tEval_GAUC: 0.6905\tEval_AUC: 0.6907\n",
      "Epoch 2 Global_step 2000\tTrain_loss: 0.6805\tEval_GAUC: 0.6903\tEval_AUC: 0.6908\n",
      "Epoch 2 Global_step 3000\tTrain_loss: 0.6804\tEval_GAUC: 0.6908\tEval_AUC: 0.6908\n",
      "Epoch 2 Global_step 4000\tTrain_loss: 0.6806\tEval_GAUC: 0.6913\tEval_AUC: 0.6908\n",
      "Epoch 2 Global_step 5000\tTrain_loss: 0.6787\tEval_GAUC: 0.6910\tEval_AUC: 0.6909\n",
      "Epoch 2 Global_step 6000\tTrain_loss: 0.6787\tEval_GAUC: 0.6898\tEval_AUC: 0.6906\n",
      "Epoch 2 Global_step 7000\tTrain_loss: 0.6784\tEval_GAUC: 0.6898\tEval_AUC: 0.6906\n",
      "Epoch 2 Global_step 8000\tTrain_loss: 0.6777\tEval_GAUC: 0.6893\tEval_AUC: 0.6908\n",
      "Epoch 2 DONE\tCost time: 691.73\n",
      "Epoch 3 Global_step 1000\tTrain_loss: 0.6766\tEval_GAUC: 0.6896\tEval_AUC: 0.6909\n",
      "Epoch 3 Global_step 2000\tTrain_loss: 0.6754\tEval_GAUC: 0.6902\tEval_AUC: 0.6910\n",
      "Epoch 3 Global_step 3000\tTrain_loss: 0.6754\tEval_GAUC: 0.6905\tEval_AUC: 0.6910\n",
      "Epoch 3 Global_step 4000\tTrain_loss: 0.6758\tEval_GAUC: 0.6914\tEval_AUC: 0.6910\n",
      "Epoch 3 Global_step 5000\tTrain_loss: 0.6738\tEval_GAUC: 0.6908\tEval_AUC: 0.6911\n",
      "Epoch 3 Global_step 6000\tTrain_loss: 0.6739\tEval_GAUC: 0.6900\tEval_AUC: 0.6909\n",
      "Epoch 3 Global_step 7000\tTrain_loss: 0.6738\tEval_GAUC: 0.6903\tEval_AUC: 0.6909\n",
      "Epoch 3 Global_step 8000\tTrain_loss: 0.6731\tEval_GAUC: 0.6896\tEval_AUC: 0.6910\n",
      "Epoch 3 DONE\tCost time: 911.75\n",
      "Epoch 4 Global_step 1000\tTrain_loss: 0.6721\tEval_GAUC: 0.6904\tEval_AUC: 0.6912\n",
      "Epoch 4 Global_step 2000\tTrain_loss: 0.6707\tEval_GAUC: 0.6904\tEval_AUC: 0.6913\n",
      "Epoch 4 Global_step 3000\tTrain_loss: 0.6710\tEval_GAUC: 0.6901\tEval_AUC: 0.6914\n",
      "Epoch 4 Global_step 4000\tTrain_loss: 0.6715\tEval_GAUC: 0.6903\tEval_AUC: 0.6914\n",
      "Epoch 4 Global_step 5000\tTrain_loss: 0.6692\tEval_GAUC: 0.6907\tEval_AUC: 0.6916\n",
      "Epoch 4 Global_step 6000\tTrain_loss: 0.6695\tEval_GAUC: 0.6904\tEval_AUC: 0.6915\n",
      "Epoch 4 Global_step 7000\tTrain_loss: 0.6694\tEval_GAUC: 0.6908\tEval_AUC: 0.6915\n",
      "Epoch 4 Global_step 8000\tTrain_loss: 0.6688\tEval_GAUC: 0.6903\tEval_AUC: 0.6917\n",
      "Epoch 4 DONE\tCost time: 1136.62\n",
      "Epoch 5 Global_step 1000\tTrain_loss: 0.6678\tEval_GAUC: 0.6902\tEval_AUC: 0.6919\n",
      "Epoch 5 Global_step 2000\tTrain_loss: 0.6663\tEval_GAUC: 0.6918\tEval_AUC: 0.6921\n",
      "Epoch 5 Global_step 3000\tTrain_loss: 0.6667\tEval_GAUC: 0.6900\tEval_AUC: 0.6922\n",
      "Epoch 5 Global_step 4000\tTrain_loss: 0.6674\tEval_GAUC: 0.6903\tEval_AUC: 0.6923\n",
      "Epoch 5 Global_step 5000\tTrain_loss: 0.6648\tEval_GAUC: 0.6904\tEval_AUC: 0.6923\n",
      "Epoch 5 Global_step 6000\tTrain_loss: 0.6651\tEval_GAUC: 0.6892\tEval_AUC: 0.6923\n",
      "Epoch 5 Global_step 7000\tTrain_loss: 0.6652\tEval_GAUC: 0.6888\tEval_AUC: 0.6919\n",
      "Epoch 5 Global_step 8000\tTrain_loss: 0.6644\tEval_GAUC: 0.6884\tEval_AUC: 0.6917\n",
      "Epoch 5 DONE\tCost time: 1357.09\n",
      "Epoch 6 Global_step 1000\tTrain_loss: 0.6633\tEval_GAUC: 0.6890\tEval_AUC: 0.6912\n",
      "Epoch 6 Global_step 2000\tTrain_loss: 0.6614\tEval_GAUC: 0.6886\tEval_AUC: 0.6895\n",
      "Epoch 6 Global_step 3000\tTrain_loss: 0.6619\tEval_GAUC: 0.6865\tEval_AUC: 0.6869\n",
      "Epoch 6 Global_step 4000\tTrain_loss: 0.6620\tEval_GAUC: 0.6842\tEval_AUC: 0.6827\n",
      "Epoch 6 Global_step 5000\tTrain_loss: 0.6582\tEval_GAUC: 0.6794\tEval_AUC: 0.6762\n",
      "Epoch 6 Global_step 6000\tTrain_loss: 0.6583\tEval_GAUC: 0.6743\tEval_AUC: 0.6708\n",
      "Epoch 6 Global_step 7000\tTrain_loss: 0.6579\tEval_GAUC: 0.6682\tEval_AUC: 0.6649\n",
      "Epoch 6 Global_step 8000\tTrain_loss: 0.6559\tEval_GAUC: 0.6630\tEval_AUC: 0.6592\n",
      "Epoch 6 DONE\tCost time: 1577.60\n",
      "Epoch 7 Global_step 1000\tTrain_loss: 0.6552\tEval_GAUC: 0.6621\tEval_AUC: 0.6589\n",
      "Epoch 7 Global_step 2000\tTrain_loss: 0.6517\tEval_GAUC: 0.6594\tEval_AUC: 0.6569\n",
      "Epoch 7 Global_step 3000\tTrain_loss: 0.6539\tEval_GAUC: 0.6577\tEval_AUC: 0.6564\n",
      "Epoch 7 Global_step 4000\tTrain_loss: 0.6534\tEval_GAUC: 0.6576\tEval_AUC: 0.6569\n",
      "Epoch 7 Global_step 5000\tTrain_loss: 0.6492\tEval_GAUC: 0.6561\tEval_AUC: 0.6555\n",
      "Epoch 7 Global_step 6000\tTrain_loss: 0.6507\tEval_GAUC: 0.6576\tEval_AUC: 0.6572\n",
      "Epoch 7 Global_step 7000\tTrain_loss: 0.6513\tEval_GAUC: 0.6589\tEval_AUC: 0.6570\n",
      "Epoch 7 Global_step 8000\tTrain_loss: 0.6497\tEval_GAUC: 0.6567\tEval_AUC: 0.6562\n",
      "Epoch 7 DONE\tCost time: 1796.40\n",
      "Epoch 8 Global_step 1000\tTrain_loss: 0.6496\tEval_GAUC: 0.6603\tEval_AUC: 0.6595\n",
      "Epoch 8 Global_step 2000\tTrain_loss: 0.6457\tEval_GAUC: 0.6583\tEval_AUC: 0.6575\n",
      "Epoch 8 Global_step 3000\tTrain_loss: 0.6485\tEval_GAUC: 0.6576\tEval_AUC: 0.6571\n",
      "Epoch 8 Global_step 4000\tTrain_loss: 0.6483\tEval_GAUC: 0.6605\tEval_AUC: 0.6588\n",
      "Epoch 8 Global_step 5000\tTrain_loss: 0.6442\tEval_GAUC: 0.6600\tEval_AUC: 0.6576\n",
      "Epoch 8 Global_step 6000\tTrain_loss: 0.6456\tEval_GAUC: 0.6605\tEval_AUC: 0.6594\n",
      "Epoch 8 Global_step 7000\tTrain_loss: 0.6465\tEval_GAUC: 0.6612\tEval_AUC: 0.6597\n",
      "Epoch 8 Global_step 8000\tTrain_loss: 0.6452\tEval_GAUC: 0.6635\tEval_AUC: 0.6600\n",
      "Epoch 8 DONE\tCost time: 2015.54\n",
      "Epoch 9 Global_step 1000\tTrain_loss: 0.6449\tEval_GAUC: 0.6653\tEval_AUC: 0.6631\n",
      "Epoch 9 Global_step 2000\tTrain_loss: 0.6405\tEval_GAUC: 0.6633\tEval_AUC: 0.6607\n",
      "Epoch 9 Global_step 3000\tTrain_loss: 0.6435\tEval_GAUC: 0.6630\tEval_AUC: 0.6605\n",
      "Epoch 9 Global_step 4000\tTrain_loss: 0.6433\tEval_GAUC: 0.6643\tEval_AUC: 0.6628\n",
      "Epoch 9 Global_step 5000\tTrain_loss: 0.6386\tEval_GAUC: 0.6654\tEval_AUC: 0.6621\n",
      "Epoch 9 Global_step 6000\tTrain_loss: 0.6396\tEval_GAUC: 0.6666\tEval_AUC: 0.6645\n",
      "Epoch 9 Global_step 7000\tTrain_loss: 0.6402\tEval_GAUC: 0.6680\tEval_AUC: 0.6657\n",
      "Epoch 9 Global_step 8000\tTrain_loss: 0.6382\tEval_GAUC: 0.6710\tEval_AUC: 0.6681\n",
      "Epoch 9 DONE\tCost time: 2236.97\n",
      "Best test_gauc:  tf.Tensor(0.69183993, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Base\n",
    "train(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Global_step 1000\tTrain_loss: 0.6931\tEval_GAUC: 0.5871\tEval_AUC: 0.5693\n",
      "Epoch 0 Global_step 2000\tTrain_loss: 0.6917\tEval_GAUC: 0.6125\tEval_AUC: 0.6007\n",
      "Epoch 0 Global_step 3000\tTrain_loss: 0.6904\tEval_GAUC: 0.6159\tEval_AUC: 0.6065\n",
      "Epoch 0 Global_step 4000\tTrain_loss: 0.6882\tEval_GAUC: 0.6075\tEval_AUC: 0.6035\n",
      "Epoch 0 Global_step 5000\tTrain_loss: 0.6825\tEval_GAUC: 0.6053\tEval_AUC: 0.6022\n",
      "Epoch 0 Global_step 6000\tTrain_loss: 0.6800\tEval_GAUC: 0.6125\tEval_AUC: 0.6107\n",
      "Epoch 0 Global_step 7000\tTrain_loss: 0.6787\tEval_GAUC: 0.6173\tEval_AUC: 0.6128\n",
      "Epoch 0 Global_step 8000\tTrain_loss: 0.6755\tEval_GAUC: 0.6198\tEval_AUC: 0.6160\n",
      "Epoch 0 DONE\tCost time: 504.41\n",
      "Epoch 1 Global_step 1000\tTrain_loss: 0.6742\tEval_GAUC: 0.6246\tEval_AUC: 0.6228\n",
      "Epoch 1 Global_step 2000\tTrain_loss: 0.6690\tEval_GAUC: 0.6267\tEval_AUC: 0.6251\n",
      "Epoch 1 Global_step 3000\tTrain_loss: 0.6695\tEval_GAUC: 0.6279\tEval_AUC: 0.6270\n",
      "Epoch 1 Global_step 4000\tTrain_loss: 0.6663\tEval_GAUC: 0.6418\tEval_AUC: 0.6394\n",
      "Epoch 1 Global_step 5000\tTrain_loss: 0.6572\tEval_GAUC: 0.6509\tEval_AUC: 0.6490\n",
      "Epoch 1 Global_step 6000\tTrain_loss: 0.6521\tEval_GAUC: 0.6655\tEval_AUC: 0.6636\n",
      "Epoch 1 Global_step 7000\tTrain_loss: 0.6460\tEval_GAUC: 0.6733\tEval_AUC: 0.6717\n",
      "Epoch 1 Global_step 8000\tTrain_loss: 0.6366\tEval_GAUC: 0.6800\tEval_AUC: 0.6805\n",
      "Epoch 1 DONE\tCost time: 1008.02\n",
      "Epoch 2 Global_step 1000\tTrain_loss: 0.6269\tEval_GAUC: 0.6821\tEval_AUC: 0.6832\n",
      "Epoch 2 Global_step 2000\tTrain_loss: 0.6165\tEval_GAUC: 0.6877\tEval_AUC: 0.6863\n",
      "Epoch 2 Global_step 3000\tTrain_loss: 0.6146\tEval_GAUC: 0.6886\tEval_AUC: 0.6874\n",
      "Epoch 2 Global_step 4000\tTrain_loss: 0.6105\tEval_GAUC: 0.6885\tEval_AUC: 0.6884\n",
      "Epoch 2 Global_step 5000\tTrain_loss: 0.5950\tEval_GAUC: 0.6888\tEval_AUC: 0.6890\n",
      "Epoch 2 Global_step 6000\tTrain_loss: 0.5904\tEval_GAUC: 0.6866\tEval_AUC: 0.6886\n",
      "Epoch 2 Global_step 7000\tTrain_loss: 0.5853\tEval_GAUC: 0.6847\tEval_AUC: 0.6868\n",
      "Epoch 2 Global_step 8000\tTrain_loss: 0.5780\tEval_GAUC: 0.6858\tEval_AUC: 0.6884\n",
      "Epoch 2 DONE\tCost time: 1509.57\n",
      "Epoch 3 Global_step 1000\tTrain_loss: 0.5765\tEval_GAUC: 0.6847\tEval_AUC: 0.6872\n",
      "Epoch 3 Global_step 2000\tTrain_loss: 0.5681\tEval_GAUC: 0.6871\tEval_AUC: 0.6879\n",
      "Epoch 3 Global_step 3000\tTrain_loss: 0.5731\tEval_GAUC: 0.6870\tEval_AUC: 0.6870\n",
      "Epoch 3 Global_step 4000\tTrain_loss: 0.5750\tEval_GAUC: 0.6839\tEval_AUC: 0.6869\n",
      "Epoch 3 Global_step 5000\tTrain_loss: 0.5607\tEval_GAUC: 0.6837\tEval_AUC: 0.6862\n",
      "Epoch 3 Global_step 6000\tTrain_loss: 0.5611\tEval_GAUC: 0.6820\tEval_AUC: 0.6854\n",
      "Epoch 3 Global_step 7000\tTrain_loss: 0.5590\tEval_GAUC: 0.6809\tEval_AUC: 0.6837\n",
      "Epoch 3 Global_step 8000\tTrain_loss: 0.5542\tEval_GAUC: 0.6837\tEval_AUC: 0.6845\n",
      "Epoch 3 DONE\tCost time: 2014.99\n",
      "Epoch 4 Global_step 1000\tTrain_loss: 0.5570\tEval_GAUC: 0.6809\tEval_AUC: 0.6836\n",
      "Epoch 4 Global_step 2000\tTrain_loss: 0.5484\tEval_GAUC: 0.6824\tEval_AUC: 0.6842\n",
      "Epoch 4 Global_step 3000\tTrain_loss: 0.5555\tEval_GAUC: 0.6824\tEval_AUC: 0.6833\n",
      "Epoch 4 Global_step 4000\tTrain_loss: 0.5600\tEval_GAUC: 0.6805\tEval_AUC: 0.6834\n",
      "Epoch 4 Global_step 5000\tTrain_loss: 0.5454\tEval_GAUC: 0.6787\tEval_AUC: 0.6827\n",
      "Epoch 4 Global_step 6000\tTrain_loss: 0.5480\tEval_GAUC: 0.6788\tEval_AUC: 0.6820\n",
      "Epoch 4 Global_step 7000\tTrain_loss: 0.5467\tEval_GAUC: 0.6788\tEval_AUC: 0.6807\n",
      "Epoch 4 Global_step 8000\tTrain_loss: 0.5431\tEval_GAUC: 0.6793\tEval_AUC: 0.6813\n",
      "Epoch 4 DONE\tCost time: 2519.03\n",
      "Epoch 5 Global_step 1000\tTrain_loss: 0.5475\tEval_GAUC: 0.6775\tEval_AUC: 0.6806\n",
      "Epoch 5 Global_step 2000\tTrain_loss: 0.5381\tEval_GAUC: 0.6792\tEval_AUC: 0.6811\n",
      "Epoch 5 Global_step 3000\tTrain_loss: 0.5457\tEval_GAUC: 0.6792\tEval_AUC: 0.6804\n",
      "Epoch 5 Global_step 4000\tTrain_loss: 0.5516\tEval_GAUC: 0.6774\tEval_AUC: 0.6805\n",
      "Epoch 5 Global_step 5000\tTrain_loss: 0.5368\tEval_GAUC: 0.6758\tEval_AUC: 0.6800\n",
      "Epoch 5 Global_step 6000\tTrain_loss: 0.5404\tEval_GAUC: 0.6751\tEval_AUC: 0.6795\n",
      "Epoch 5 Global_step 7000\tTrain_loss: 0.5391\tEval_GAUC: 0.6759\tEval_AUC: 0.6783\n",
      "Epoch 5 Global_step 8000\tTrain_loss: 0.5362\tEval_GAUC: 0.6767\tEval_AUC: 0.6788\n",
      "Epoch 5 DONE\tCost time: 3024.95\n",
      "Epoch 6 Global_step 1000\tTrain_loss: 0.5418\tEval_GAUC: 0.6741\tEval_AUC: 0.6783\n",
      "Epoch 6 Global_step 2000\tTrain_loss: 0.5317\tEval_GAUC: 0.6773\tEval_AUC: 0.6788\n",
      "Epoch 6 Global_step 3000\tTrain_loss: 0.5392\tEval_GAUC: 0.6762\tEval_AUC: 0.6781\n",
      "Epoch 6 Global_step 4000\tTrain_loss: 0.5453\tEval_GAUC: 0.6745\tEval_AUC: 0.6782\n",
      "Epoch 6 Global_step 5000\tTrain_loss: 0.5308\tEval_GAUC: 0.6733\tEval_AUC: 0.6778\n",
      "Epoch 6 Global_step 6000\tTrain_loss: 0.5357\tEval_GAUC: 0.6740\tEval_AUC: 0.6775\n",
      "Epoch 6 Global_step 7000\tTrain_loss: 0.5343\tEval_GAUC: 0.6734\tEval_AUC: 0.6765\n",
      "Epoch 6 Global_step 8000\tTrain_loss: 0.5306\tEval_GAUC: 0.6753\tEval_AUC: 0.6769\n",
      "Epoch 6 DONE\tCost time: 3528.25\n",
      "Epoch 7 Global_step 1000\tTrain_loss: 0.5372\tEval_GAUC: 0.6719\tEval_AUC: 0.6765\n",
      "Epoch 7 Global_step 2000\tTrain_loss: 0.5267\tEval_GAUC: 0.6739\tEval_AUC: 0.6769\n",
      "Epoch 7 Global_step 3000\tTrain_loss: 0.5352\tEval_GAUC: 0.6736\tEval_AUC: 0.6764\n",
      "Epoch 7 Global_step 4000\tTrain_loss: 0.5405\tEval_GAUC: 0.6719\tEval_AUC: 0.6764\n",
      "Epoch 7 Global_step 5000\tTrain_loss: 0.5246\tEval_GAUC: 0.6715\tEval_AUC: 0.6758\n",
      "Epoch 7 Global_step 6000\tTrain_loss: 0.5313\tEval_GAUC: 0.6716\tEval_AUC: 0.6755\n",
      "Epoch 7 Global_step 7000\tTrain_loss: 0.5319\tEval_GAUC: 0.6714\tEval_AUC: 0.6749\n",
      "Epoch 7 Global_step 8000\tTrain_loss: 0.5265\tEval_GAUC: 0.6729\tEval_AUC: 0.6755\n",
      "Epoch 7 DONE\tCost time: 4031.45\n",
      "Epoch 8 Global_step 1000\tTrain_loss: 0.5318\tEval_GAUC: 0.6709\tEval_AUC: 0.6749\n",
      "Epoch 8 Global_step 2000\tTrain_loss: 0.5207\tEval_GAUC: 0.6719\tEval_AUC: 0.6751\n",
      "Epoch 8 Global_step 3000\tTrain_loss: 0.5315\tEval_GAUC: 0.6710\tEval_AUC: 0.6746\n",
      "Epoch 8 Global_step 4000\tTrain_loss: 0.5384\tEval_GAUC: 0.6701\tEval_AUC: 0.6748\n",
      "Epoch 8 Global_step 5000\tTrain_loss: 0.5192\tEval_GAUC: 0.6694\tEval_AUC: 0.6740\n",
      "Epoch 8 Global_step 6000\tTrain_loss: 0.5231\tEval_GAUC: 0.6691\tEval_AUC: 0.6730\n",
      "Epoch 8 Global_step 7000\tTrain_loss: 0.5281\tEval_GAUC: 0.6702\tEval_AUC: 0.6726\n",
      "Epoch 8 Global_step 8000\tTrain_loss: 0.5251\tEval_GAUC: 0.6714\tEval_AUC: 0.6739\n",
      "Epoch 8 DONE\tCost time: 4535.77\n",
      "Epoch 9 Global_step 1000\tTrain_loss: 0.5251\tEval_GAUC: 0.6697\tEval_AUC: 0.6730\n",
      "Epoch 9 Global_step 2000\tTrain_loss: 0.5107\tEval_GAUC: 0.6691\tEval_AUC: 0.6727\n",
      "Epoch 9 Global_step 3000\tTrain_loss: 0.5232\tEval_GAUC: 0.6681\tEval_AUC: 0.6721\n",
      "Epoch 9 Global_step 4000\tTrain_loss: 0.5336\tEval_GAUC: 0.6676\tEval_AUC: 0.6722\n",
      "Epoch 9 Global_step 5000\tTrain_loss: 0.5160\tEval_GAUC: 0.6685\tEval_AUC: 0.6718\n",
      "Epoch 9 Global_step 6000\tTrain_loss: 0.5099\tEval_GAUC: 0.6646\tEval_AUC: 0.6684\n",
      "Epoch 9 Global_step 7000\tTrain_loss: 0.5104\tEval_GAUC: 0.6627\tEval_AUC: 0.6662\n",
      "Epoch 9 Global_step 8000\tTrain_loss: 0.5133\tEval_GAUC: 0.6665\tEval_AUC: 0.6690\n",
      "Epoch 9 DONE\tCost time: 5040.17\n",
      "Best test_gauc:  tf.Tensor(0.68882537, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# DIN\n",
    "model = DIN(user_count, item_count, cate_count, cate_list,\n",
    "            args.user_dim, args.item_dim, args.cate_dim, args.dim_layers)\n",
    "train(optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (PycharmProjects)",
   "language": "python",
   "name": "pycharm-53e69571"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
